loading annotations into memory...
Done (t=26.93s)
creating index...
index created!
Train Image Count: 280741
Train Class Count: 2
  0. BG
  1. building
loading annotations into memory...
Done (t=6.86s)
creating index...
index created!
Val Image Count: 60317
Val Class Count: 2
  0. BG
  1. building
logs/2024-10-22_17-47-03/maskrcnn_resnet50_fpn_v2.pth
/home/your_email/iptu/samples/mapping/main.py:241: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler() if device.type == 'cuda' and use_scaler else None
Epochs:   0%|                                                                                                                   | 0/40 [00:16<?, ?it/s]
GPU disponível. Treinamento iniciará na GPU.
Traceback (most recent call last):                                            | 28/70186 [00:16<10:21:29,  1.88it/s, loss=1.03, avg_loss=1.81, lr=2e-5]
  File "/home/your_email/iptu/samples/mapping/main.py", line 348, in <module>
    main(dataset_dir=dataset_dir, epochs=epochs, size=size, class_names=class_names)
  File "/home/your_email/iptu/samples/mapping/main.py", line 324, in main
    train_loop(model=model,
  File "/home/your_email/iptu/samples/mapping/main.py", line 247, in train_loop
    train_loss = run_epoch(model, train_dataloader, optimizer, lr_scheduler, device, scaler, epoch, is_training=True)
  File "/home/your_email/iptu/samples/mapping/main.py", line 167, in run_epoch
    losses = model(inputs.to(device), move_data_to_device(targets, device))
  File "/home/your_email/miniconda/envs/iptu310/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/your_email/miniconda/envs/iptu310/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/your_email/miniconda/envs/iptu310/lib/python3.10/site-packages/torchvision/models/detection/generalized_rcnn.py", line 83, in forward
    images, targets = self.transform(images, targets)
  File "/home/your_email/miniconda/envs/iptu310/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/your_email/miniconda/envs/iptu310/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/your_email/miniconda/envs/iptu310/lib/python3.10/site-packages/torchvision/models/detection/transform.py", line 142, in forward
    image, target_index = self.resize(image, target_index)
  File "/home/your_email/miniconda/envs/iptu310/lib/python3.10/site-packages/torchvision/models/detection/transform.py", line 191, in resize
    image, target = _resize_image_and_masks(image, size, self.max_size, target, self.fixed_size)
  File "/home/your_email/miniconda/envs/iptu310/lib/python3.10/site-packages/torchvision/models/detection/transform.py", line 79, in _resize_image_and_masks
    mask = torch.nn.functional.interpolate(
  File "/home/your_email/miniconda/envs/iptu310/lib/python3.10/site-packages/torch/nn/functional.py", line 4536, in interpolate
    return torch._C._nn.upsample_nearest2d(input, output_size, scale_factors)
RuntimeError: Input and output sizes should be greater than 0, but got input (H: 0, W: 0) output (H: 0, W: 0)
